?sample()
?sample()
set.seed(898)
?Normal
x = seq(-3,3, by = .01)
head(x)
dnorm(0, 1, 1)
dnorm(0, mean = 1, sd = 1)
plot(x, dnorm(x), type="l")
pnorm(0)
?Normal
dnorm(0)
x = seq(-3,4, by = .01)
dnorm(0)
x = seq(-3,3, by = .01)
pnorm(1.96)
plot(x, dnorm(x), type="l")
pnorm(0)
pnorm(1.96)
plot(x, pnorm(x), type="l")
pnorm(1) - pnorm(-1)
qnorm(.5)
qnorm(.975)
qnorm(.9)
qnorm(1)
qnorm(0.99991)
qnorm(.9)
rnorm(1)
rnorm(100)
main = "Draws from a Standard Normal Distribution", xlab = NULL)
hist(rnorm(100), breaks = 50,
main = "Draws from a Standard Normal Distribution", xlab = NULL)
hist(rnorm(1000), breaks = 50,
main = "Draws from a Standard Normal Distribution", xlab = NULL)
hist(rnorm(10000), breaks = 50,
main = "Draws from a Standard Normal Distribution", xlab = NULL)
?Uniform
dunif(0.5)
dunif(1.5)
dnorm(0, 1, 1)
dunif(1.5)
dunif(0.5, min = 0, max = 2)
punif(0.5)
plot(x, punif(x), type = "l")
qunif(0.5)
runif(100)
hist(runif(100), breaks = 20,
main = "Draws from a Uniform Distribution", xlab = NULL)
hist(runif(1000), breaks = 20,
main = "Draws from a Uniform Distribution", xlab = NULL)
hist(runif(10000), breaks = 20,
main = "Draws from a Uniform Distribution", xlab = NULL)
hist(runif(10000000), breaks = 20,
main = "Draws from a Uniform Distribution", xlab = NULL)
hist(runif(10000), breaks = 20,
main = "Draws from a Uniform Distribution", xlab = NULL)
x = seq(-3,3, by = 0.1)
head(x)
coin = c('Head', 'Tail')
H=0, T=1
coin = c('Head', 'Tail')
H=0, T=1
s.coin = sample (coin, size = 3, replace = T)
mean(s.coin == 'Tail')
?dbinom
dbinom(x=3, size = 3, prob=1/2)
success.0 =  dbinom(x=0 , size = 3, prob=1/2)
success.1 =  dbinom(x=1 , size = 3, prob=1/2)
success.2 =  dbinom(x=2 , size = 3, prob=1/2)
value = success.0*2
value =
value
coin = c('Head', 'Tail')
value = 2*2
value
value = success.0*2
value
success.0
multvalue = 6 - [(success.0 * 0) + (success.1 * 2) + (success.2 * 4)]
multvalue = 6 - ((success.0 * 0) + (success.1 * 2) + (success.2 * 4))
multvalue
paid.0 = 0
paid.1 = 2
paid.2 = 4
multvalue = 6 - ((success.0 * paid.0) + (success.1 * paid.1) + (success.2 * paid.2))
multvalue
success.3 =  dbinom(x=3 , size = 3, prob=1/2)
paid.3 = multvalue/success.3
paid.3
success.0*paid.0 + success.1*paid.1 + success.2*paid.2 + success.3*paid.3
success.0*paid.0 + success.1*paid.1 + success.2*paid.2 + success.3*paid.3
\usepackage{amsmath}
usepackage{amsmath}
package(amsmath)
\documentclass{article}
\begin{document}
\[   \left\{
\begin{array}{ll}
0 & x\leq a \\
\frac{x-a}{b-a} & a\leq x\leq b \\
\frac{c-x}{c-b} & b\leq x\leq c \\
1 & c\leq x \\
\end{array}
\right. \]
\end{document}
\documentclass{article}
\begin{document}
\[   \left\{
\begin{array}{ll}
0 & x\leq a \\
\frac{x-a}{b-a} & a\leq x\leq b \\
\frac{c-x}{c-b} & b\leq x\leq c \\
1 & c\leq x \\
\end{array}
\right. \]
\end{document}
success.0 =  dbinom(x=0 , size = 3, prob=1/2)
success.0 =  dbinom(x=0 , size = 3, prob=1/2)
(success.0 =  dbinom(x=0 , size = 3, prob=1/2))
(success.1 =  dbinom(x=1 , size = 3, prob=1/2))
mean(x)
t = runif(N)
x = 100 * (1-t)^(1/2)
mean(x)
N = 1e4
t = runif(N)
x = 100 * (1-t)^(1/2)
mean(x)
CDF = seq(1,N)/N
plot(CDF ~ x.sorted, type = 'l', lwd = 2, col = 'red')
x.sorted = sort(x)
CDF = seq(1,N)/N
plot(CDF ~ x.sorted, type = 'l', lwd = 2, col = 'red')
x.base = seq(1,100, by = 0.1)
CDF.th = (x / 100)^(1/2)
lines CDF ~ x.sorted, lwd = 1, col = 'blue')
lines (CDF ~ x.sorted, lwd = 1, col = 'blue')
plot(CDF ~ x.sorted, type = 'l', lwd = 3, col = 'red')
x.base = seq(1,100, by = 0.1)
CDF.th = (x / 100)^(1/2)
lines (CDF ~ x.sorted, lwd = 1, col = 'blue')
CDF.th = (x / 100)^(1/2)
lines (CDF.th ~ x.sorted, lwd = 1, col = 'blue')
x.base = seq(1,100, by = 0.1)
CDF.th = (x.base / 100)^(1/2)
lines (CDF.th ~ x.base, lwd = 1, col = 'blue')
plot(CDF ~ x.sorted, type = 'l', lwd = 3, col = 'red')
lines (CDF.th ~ x.base, lwd = 1, col = 'blue')
x.base = seq(1,100, by = 0.1)
CDF.th = (x.base / 100)^2
lines (CDF.th ~ x.base, lwd = 1, col = 'blue')
plot(CDF ~ x.sorted, type = 'l', lwd = 3, col = 'red')
lines (CDF.th ~ x.base, lwd = 1, col = 'blue')
lines (CDF.th ~ x.base, lwd = 1, col = 'green', lty=2)
?sorted
a = 2
y =  runif(N)
x = runif(N,  min = a*y , max = a*y+ 1)
ex = mean(x)
ey = mean(y)
exy = mean(x*y)
( cov_xy = exy - ex* ey  )
( theoretical_cov_xy = a/12 )
a = 12
y =  runif(N)
x = runif(N,  min = a*y , max = a*y+ 1)
ex = mean(x)
ey = mean(y)
exy = mean(x*y)
( cov_xy = exy - ex* ey  )
( theoretical_cov_xy = a/12 )
variance(vec)
vec = c(1,2,3,4,16,17,18,19,20)
variance(vec)
samplemean = mean(vec)
vec = c(1,2,3,4,16,17,18,19,20)
variance(vec)
variance = function(x)
variance = function(x)
{
samplemean = mean(x)
output = sum((x-mean)^2)
return(output)
}
vec = c(1,2,3,4,16,17,18,19,20)
variance(vec)
variance(vec)
variance(vec)
variance = function(x)
{
samplemean = mean(x)
output = sum((x-samplemean)^2)
return(output)
}
vec = c(1,2,3,4,16,17,18,19,20)
variance(vec)
variance = function(x)
{
#to accomdate for missing values
xx = x[!is.na(x)]
samplemean = mean(xx)
output = sum((xx-samplemean)^2)/n
return(output)
}
vec = c(1,2,3,4,16,17,18,19,20)
variance(vec)
variance(vec)
variance = function(x)
{
#to accomdate for missing values
xx = x[!is.na(x)]
n = length(xx)
samplemean = mean(xx)
output = sum((xx-samplemean)^2)
return(output/n)
}
vec = c(1,2,3,4,16,17,18,19,20)
variance(vec)
variance = function(x)
{
#to accomdate for missing values
xx = x[!is.na(x)]
n = length(xx)
samplemean = mean(xx)
output = sum((xx-samplemean)^2)
return(output/n-1)
}
vec = c(1,2,3,4,16,17,18,19,20)
variance(vec)
samplesize=10
variance( runif(samplesize) )
myvar = replicate(10 )
variance( runif(samplesize) )
variance( runif(samplesize) )
myvar = replicate(10 )
?replicate
?replicate
myvar = replicate(variance( runif(samplesize) ) )
mean(myvar)
1/12
variance( runif(samplesize))
myvar = replicate(10, variance( runif(samplesize) ))
(myvar = replicate(10, variance( runif(samplesize) )))
mean(myvar)
(myvar = replicate(samplesize, variance( runif(samplesize) )))
1/12
variance( runif(samplesize))
(myvar = replicate(samplesize, variance( runif(samplesize) )))
mean(myvar)
(myvar = replicate(variance(samplesize))
mean(myvar)
1/12
(myvar = replicate(variance(samplesize))
(myvar = replicate(samplesize, variance( runif(samplesize) )))
mean(myvar)
mean(myvar)
(myvar = replicate(samplesize, variance( runif(samplesize) )))
mean(myvar)
myvar = replicate( K )
samplesize=10000
variance( runif(samplesize) )
K = 1000
myvar = replicate( K )
bias = numeric(0)
bias = numeric(0)
sz  = c(5,50,500,5000)
for (samplesize  in sz) {
k=1000
myvar = replicate(k, variance( runif(samplesize) ) )
bias = c(bias,  1/12 - mean(myvar) )
}
plot(sz , bias )
bias = numeric(0)
sz  = c(5,50,500,5000)
for (samplesize  in sz) {
k=1000
myvar = replicate(k, variance( runif(samplesize) ) )
bias = c(bias,  1/12 - mean(myvar) )
}
plot(sz , bias , type='l' )
bias = numeric(0)
sz  = c(5,20, 50,100, 250, 500,5000)
for (samplesize  in sz) {
k=1000
myvar = replicate(k, variance( runif(samplesize) ) )
bias = c(bias,  1/12 - mean(myvar) )
}
plot(sz , bias , type='l' )
f = function (x)
return( x^2 - 7*x + 12)
# testing the function
f(0)
f(0)
f(1)
opt = optim(par = runif(1), fn = f)
print(opt)
library(MASS)
N = 1e3
X = mvrnorm(N, mu = c(0,2), Sigma = matrix(c(2,.7, .7, 1),ncol=2 ) )
x1 = X[,1]
x2 = X[,2]
y = -6 + 3 * x2 + rnorm(N,sd = 2)
df = data.frame(x1,x2,y)
summary(lm(y~x1+x2, data = df))
corr(x1,y)
cor(x1,x2)
summary(lm(y~x1, data=df))
summary(lm(y~x1+x2, data = df))
dfsel1 = subset(df , df$x1 > mean(df$x1)  ) #only takes observations above avg for x1
dfsel2 = subset(df , df$x2 > mean(df$x2)  ) #only take observations above avg for x2
dfsel3 = subset(df , df$y > mean(df$y)  ) #only take observations above avg for y
dfsel4 = subset(df , ( df$x1 > mean(df$x1) & df$y > mean(df$y) )  |
( df$x1 < mean(df$x1) & df$y < mean(df$y) )  )
scatterPlot(dfsel1)
scatterPlotMatrix(dfsel1)
scatterplot(y~x1, data = df)
library(car)
scatterplot(y~x1, data = df)
scatterplot(lm(y~x2)$residuals~x1, data = df)
scatterplot(y~x1, data = dfsel1)
scatterplot(y~x1, data = dfsel2)
scatterplot(y~x1, data = dfsel3)
scatterplot(y~x1, data = dfsel4)
scatterplot(y~x1, data = dfsel4)
scatterplot(y~x1, data = dfsel1)
summary(lm( y~x1+x2, data=df) )
setwd("~/Desktop/MIDS/DivyaGitHub/TpT-BikeShareKaggle/")
#libraries
library(car)
library(lmtest) #regression with heteroskadasticity
library(sandwich) #regression with heteroskadasticity
library(stargazer)
library(effsize) #for cohen's d (practical significance)
library(rpart) #for tree
library(Metrics) #for rmsle
library(party)
train = read.csv("train.csv", sep = ',')
train = read.csv("../TpT-BikeShareKaggle/Data_Files/train.csv", sep = ',')
train = read.csv("../TpT-BikeShareKaggle/Data_Files/train.csv", sep = ',')
train_data = read.csv("../TpT-BikeShareKaggle/Data_Files/train_data.csv", sep = ',')
dev_data = read.csv("../TpT-BikeShareKaggle/Data_Files/dev_data.csv", sep = ',')
test_data = read.csv("../TpT-BikeShareKaggle/Data_Files/test_data.csv", sep = ',')
formula_ctree = count ~ hour + temp + humidity + season + weather + dayofweek #+ windspeed + month + workingday
#fitting forumula to the model
fit_ctree = ctree(formula_ctree, data=train_data)
#tells us the importance of each variable in the model
fit_ctree
#dev_data
predict_ctree_dev = predict(fit_ctree, dev_data)
# putting our predictions + hours into dataframe
submit_ctree_dev = data.frame(datetime = dev_data$datetime, count=predict_ctree_dev)
#checking root mean squared log error (like the evaluation in kaggle)
rmsle(dev_data$count, abs(predict_ctree_dev))
formula_ctree = count ~ hour + temp + humidity + season + weather + dayofweek + windspeed + month + workingday
#fitting forumula to the model
fit_ctree = ctree(formula_ctree, data=train_data)
#dev_data
predict_ctree_dev = predict(fit_ctree, dev_data)
# putting our predictions + hours into dataframe
submit_ctree_dev = data.frame(datetime = dev_data$datetime, count=predict_ctree_dev)
#checking root mean squared log error (like the evaluation in kaggle)
rmsle(dev_data$count, abs(predict_ctree_dev))
summary(train_data)
# choosing the variables to include in the model
formula_rpart = count ~ hour + temp + humidity + season + weather + dayofweek + windspeed + month + workingday
# fitting forumula to the model
fit_rpart = rpart(formula_rpart, data=train_data)
#dev_data
predict_rpart_dev = predict(fit_rpart, dev_data)
# putting our predictions + hours into dataframe
submit_rpart_dev = data.frame(datetime = dev_data$datetime, count=predict_rpart_dev)
#checking root mean squared log error (like the evaluation in kaggle)
rmsle(dev_data$count, abs(predict_rpart_dev))
predict_ctree_dev = predict(fit_ctree, dev_data)
# putting our predictions + hours into dataframe
submit_ctree_dev = data.frame(datetime = dev_data$datetime, count=predict_ctree_dev)
#checking root mean squared log error (like the evaluation in kaggle)
rmsle(dev_data$count, abs(predict_ctree_dev))
formula_ctree = count ~ hour + temp + humidity + season + weather + dayofweek + windspeed  + workingday
#fitting forumula to the model
fit_ctree = ctree(formula_ctree, data=train_data)
#dev_data
predict_ctree_dev = predict(fit_ctree, dev_data)
# putting our predictions + hours into dataframe
submit_ctree_dev = data.frame(datetime = dev_data$datetime, count=predict_ctree_dev)
#checking root mean squared log error (like the evaluation in kaggle)
rmsle(dev_data$count, abs(predict_ctree_dev))
formula_ctree = count ~ hour + temp + humidity + season + weather + dayofweek + windspeed + month
#fitting forumula to the model
fit_ctree = ctree(formula_ctree, data=train_data)
predict_ctree_dev = predict(fit_ctree, dev_data)
# putting our predictions + hours into dataframe
submit_ctree_dev = data.frame(datetime = dev_data$datetime, count=predict_ctree_dev)
#checking root mean squared log error (like the evaluation in kaggle)
rmsle(dev_data$count, abs(predict_ctree_dev))
formula_ctree = count ~ (hour^2) + temp + humidity + season + weather + dayofweek + windspeed + month + workingday
fit_ctree = ctree(formula_ctree, data=train_data)
predict_ctree_dev = predict(fit_ctree, dev_data)
submit_ctree_dev = data.frame(datetime = dev_data$datetime, count=predict_ctree_dev)
rmsle(dev_data$count, abs(predict_ctree_dev))
write.csv(submit_ctree_test, file="../TpT-BikeShareKaggle/Data_Files/submit_ctree_test_changedseasonsfewvariables.csv",row.names=FALSE)
write.csv(submit_rpart_test, file="../TpT-BikeShareKaggle/Data_Files/submit_rpart_test_v34.csv",row.names=FALSE)
predict_rpart_test = predict(fit_rpart, test_data)
submit_rpart_test = data.frame(datetime = test_data$datetime, count=predict_rpart_test)
write.csv(submit_rpart_test, file="../TpT-BikeShareKaggle/Data_Files/submit_rpart_test_v34.csv",row.names=FALSE)
write.csv(submit_rpart_test, file="../Data_Files/submit_rpart_test_v34.csv",row.names=FALSE)
write.csv(submit_rpart_test, file="../TpT-BikeShareKaggle/Orig_Data_Files/submit_rpart_test_v34.csv",row.names=FALSE)
write.csv(submit_rpart_test, file="../TpT-BikeShareKaggle/Submissions/rpart/submit_rpart_test_v1.csv",row.names=FALSE)
write.csv(submit_ctree_test, file="../TpT-BikeShareKaggle/Submissions/party/submit_ctree_test_changedseasonsfewvariables.csv",row.names=FALSE)
predict_ctree_test = predict(fit_ctree, test_data)
# putting our predictions + hours into dataframe
submit_ctree_test = data.frame(datetime = test_data$datetime, count=predict_ctree_test)
# writing the dataframe to a csv file --> submit to kaggle
write.csv(submit_ctree_test, file="../TpT-BikeShareKaggle/Submissions/party/submit_ctree_test_changedseasonsfewvariables.csv",row.names=FALSE)
library(randomForest)
install.packages(randomForest)
install.packages("randomForest")
library(randomForest)
formula_rf = count ~ hour + temp + humidity + season + weather + dayofweek + windspeed + month + workingday
rf_model = randomForest(formula_rpart, data=train_data)
predict_rf_dev = predict(rf_model, dev_data)
submit_rf_dev = data.frame(datetime = dev_data$datetime, count=predict_rf_dev)
rmsle(dev_data$count, abs(predict_rf_dev))
print(rf_model)
?randomForest
rf_model = randomForest(formula_rpart, data=train_data, ntree = 250)
print(rf_model)
predict_rf_dev = predict(rf_model, dev_data)
submit_rf_dev = data.frame(datetime = dev_data$datetime, count=predict_rf_dev)
rmsle(dev_data$count, abs(predict_rf_dev))
setwd("~/Desktop/MIDS/DivyaGitHub/TpT-BikeShareKaggle/")
library(rpart) #for tree
library(Metrics) #for rmsle
library(party)
library(randomForest)
train = read.csv("../TpT-BikeShareKaggle/Data_Files/train.csv", sep = ',')
train_data = read.csv("../TpT-BikeShareKaggle/Data_Files/train_data.csv", sep = ',')
dev_data = read.csv("../TpT-BikeShareKaggle/Data_Files/dev_data.csv", sep = ',')
test_data = read.csv("../TpT-BikeShareKaggle/Data_Files/test_data.csv", sep = ',')
library(rpart) #for tree
library(Metrics) #for rmsle
library(party)
library(randomForest)
train = read.csv("../TpT-BikeShareKaggle/Data_Files/train.csv", sep = ',')
train_data = read.csv("../TpT-BikeShareKaggle/FeatureEng_Data_Files/train_data.csv", sep = ',')
dev_data = read.csv("../TpT-BikeShareKaggle/FeatureEng_Data_Files/dev_data.csv", sep = ',')
test_data = read.csv("../TpT-BikeShareKaggle/FeatureEng_Data_Files/test_data.csv", sep = ',')
summary(train_data)
# choosing the variables to include in the model
formula_rpart = count ~ hour + temp + humidity + season + weather + dayofweek + windspeed + month + workingday
# fitting forumula to the model
fit_rpart = rpart(formula_rpart, data=train_data)
predict_rpart_dev = predict(fit_rpart, dev_data)
# putting our predictions + hours into dataframe
submit_rpart_dev = data.frame(datetime = dev_data$datetime, count=predict_rpart_dev)
#checking root mean squared log error (like the evaluation in kaggle)
rmsle(dev_data$count, abs(predict_rpart_dev))
#test_data
predict_rpart_test = predict(fit_rpart, test_data)
# putting our predictions + hours into dataframe
submit_rpart_test = data.frame(datetime = test_data$datetime, count=predict_rpart_test)
# writing the dataframe to a csv file --> submit to kaggle
write.csv(submit_rpart_test, file="../TpT-BikeShareKaggle/Submissions/rpart/submit_rpart_test_v1.csv",row.names=FALSE)
formula_ctree = count ~ hour + temp + humidity + season + weather + dayofweek + windspeed + month + workingday
#fitting forumula to the model
fit_ctree = ctree(formula_ctree, data=train_data)
#dev_data
predict_ctree_dev = predict(fit_ctree, dev_data)
# putting our predictions + hours into dataframe
submit_ctree_dev = data.frame(datetime = dev_data$datetime, count=predict_ctree_dev)
#checking root mean squared log error (like the evaluation in kaggle)
rmsle(dev_data$count, abs(predict_ctree_dev))
predict_ctree_test = predict(fit_ctree, test_data)
# putting our predictions + hours into dataframe
submit_ctree_test = data.frame(datetime = test_data$datetime, count=predict_ctree_test)
# writing the dataframe to a csv file --> submit to kaggle
write.csv(submit_ctree_test, file="../TpT-BikeShareKaggle/Submissions/party/submit_ctree_test_changedseasonsfewvariables.csv",row.names=FALSE)
# choosing the variables to include in the model
formula_rf = count ~ hour + temp + humidity + season + weather + dayofweek + windspeed + month + workingday
# fitting forumula to the model
rf_model = randomForest(formula_rpart, data=train_data, ntree = 250)
#dev_data
predict_rf_dev = predict(rf_model, dev_data)
# putting our predictions + hours into dataframe
submit_rf_dev = data.frame(datetime = dev_data$datetime, count=predict_rf_dev)
#checking root mean squared log error (like the evaluation in kaggle)
rmsle(dev_data$count, abs(predict_rf_dev))
rmsle(dev_data$count, abs(predict_rf_dev))
#test_data
predict_rf_test = predict(rf_model, test_data)
# putting our predictions + hours into dataframe
submit_rf_test = data.frame(datetime = test_data$datetime, count=predict_rf_test)
# writing the dataframe to a csv file --> submit to kaggle
write.csv(submit_rf_test, file="../TpT-BikeShareKaggle/Submissions/randomforest/submit_rf_test_changedseasonsfewvariables.csv",row.names=FALSE)
print(rf_model)
formula_rf = count ~ hour + temp + humidity + season + weather + dayofweek + month + workingday
rf_model = randomForest(formula_rpart, data=train_data, ntree = 250)
predict_rf_dev = predict(rf_model, dev_data)
submit_rf_dev = data.frame(datetime = dev_data$datetime, count=predict_rf_dev)
rmsle(dev_data$count, abs(predict_rf_dev))
#test_data
predict_rf_test = predict(rf_model, test_data)
# putting our predictions + hours into dataframe
submit_rf_test = data.frame(datetime = test_data$datetime, count=predict_rf_test)
# writing the dataframe to a csv file --> submit to kaggle
write.csv(submit_rf_test, file="../TpT-BikeShareKaggle/Submissions/randomforest/submit_rf_test_250trees3var.csv",row.names=FALSE)
formula_rf = count ~ hour + temp + humidity + season + weather + dayofweek + month + workingday
rf_model = randomForest(formula_rpart, data=train_data, ntree = 250)
predict_rf_dev = predict(rf_model, dev_data)
submit_rf_dev = data.frame(datetime = dev_data$datetime, count=predict_rf_dev)
rmsle(dev_data$count, abs(predict_rf_dev))
write.csv(submit_rf_test, file="../TpT-BikeShareKaggle/Submissions/randomforest/submit_rf_test_250trees3var_removedwindspeed.csv",row.names=FALSE)
