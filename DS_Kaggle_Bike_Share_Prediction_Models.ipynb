{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KAGGLE BIKE SHARE CHALLENGE - Prediction Models - Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For TpT Interview Assignment - June 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By: Divya Sriram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SK-learn libraries for evaluation.\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#libraries I may need for training + modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in training and dev data sets\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10886, 12)\n",
      "(6493, 9)\n"
     ]
    }
   ],
   "source": [
    "print train.shape\n",
    "print test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create new data frames and keep original train and test sets intact for reference\n",
    "\n",
    "train_data = train\n",
    "test_data = test\n",
    "\n",
    "#separating dates into year, month, day, hour\n",
    "train_data[\"datetime\"] = pd.to_datetime(train_data[\"datetime\"])\n",
    "train_data[\"year\"] = train_data[\"datetime\"].dt.year\n",
    "train_data[\"month\"] = train_data[\"datetime\"].dt.month\n",
    "train_data[\"day\"] = train_data[\"datetime\"].dt.day\n",
    "train_data[\"hour\"] = train_data[\"datetime\"].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
       "0 2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
       "1 2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
       "2 2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
       "3 2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
       "4 2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
       "\n",
       "   humidity  windspeed  casual  registered  count  year  month  day  hour  \n",
       "0        81        0.0       3          13     16  2011      1    1     0  \n",
       "1        80        0.0       8          32     40  2011      1    1     1  \n",
       "2        80        0.0       5          27     32  2011      1    1     2  \n",
       "3        75        0.0       3          10     13  2011      1    1     3  \n",
       "4        75        0.0       0           1      1  2011      1    1     4  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#splitting train_data into train and dev\n",
    "# I believe the scikit learn's train_test_split shuffles the data in this step \n",
    "train_data, dev_data = train_test_split(train_data, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creating the labels\n",
    "train_labels = train_data['count']\n",
    "dev_labels = dev_data['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dropping the prediction label (count) for the train data set\n",
    "train_data = train_data.drop('count', 1)\n",
    "dev_data = dev_data.drop('count', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will divide the train_data set into a training and development (dev) set: 80,20 respectively. I will use the new train_data set (80% of original train_data set) to train my model and use the dev set (20% of th e original train_data set) to test the model. This allows you to test your model against a set of data you have kept aside and make changes accordingly -- using the entire training data might result in a greater accuracy for that particular training set, but is highly prone to overfitting to the training data and performing poorly with test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prep the test set like we did train_data\n",
    "test_data = test\n",
    "test_data[\"datetime\"] = pd.to_datetime(test_data[\"datetime\"])\n",
    "test_data[\"year\"] = test_data[\"datetime\"].dt.year\n",
    "test_data[\"month\"] = test_data[\"datetime\"].dt.month\n",
    "test_data[\"day\"] = test_data[\"datetime\"].dt.day\n",
    "test_data[\"hour\"] = test_data[\"datetime\"].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the training data set is:  (8708, 15)\n",
      "The size of the dev data set is:  (2178, 15)\n",
      "The size of the test data set is:  (6493, 13)\n"
     ]
    }
   ],
   "source": [
    "print \"The size of the training data set is: \", train_data.shape\n",
    "print \"The size of the dev data set is: \", dev_data.shape\n",
    "print \"The size of the test data set is: \", test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['hour']\n",
    "#cols = ['hour', 'temp', 'humidity', 'season', 'weather']\n",
    "train_data_cols = train_data[cols]\n",
    "dev_data_cols = dev_data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Classifier:\n",
      "  Optimal k for k nearest neighbors classifier: 2\n",
      "  The F1 score for the nearest neighbor classifier is:0.013016240187406077\n",
      "\n",
      "\n",
      "\n",
      "Multinomial Naive Bayes Classifier:\n",
      "  Optimal alpha for multinomial naive bayes classifier:0.1\n",
      "  The F1 score for the multinomial nb classifier is:0.0092976459939882149\n",
      "\n",
      "\n",
      "Logistic Regression Model:\n",
      "  Optimal C for logistic regression model is:1\n",
      "  The F1 score for the logistic regression classifier is:0.0078913964470025515\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    " def P3(k_values):\n",
    "    \n",
    "    ########### K NEAREST NEIGHBORS ###########\n",
    "    \n",
    "    # optimal k for knn with GridSearchCV.\n",
    "    n_neighbors = {'n_neighbors': k_values}\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn_gs = GridSearchCV(knn, n_neighbors, scoring='f1_weighted')\n",
    "    knn_gs.fit(train_data_cols, train_labels)\n",
    "    opt_k = knn_gs.best_params_['n_neighbors']\n",
    "    print \"K-Nearest Neighbors Classifier:\"\n",
    "    print \"  Optimal k for k nearest neighbors classifier: {0}\".format(opt_k)\n",
    "\n",
    "    # f1_score with best k for knn\n",
    "    knn_opt = KNeighborsClassifier(n_neighbors = opt_k)\n",
    "    knn_opt.fit(train_data_cols, train_labels)\n",
    "    knn_preds = knn_opt.predict(dev_data_cols)\n",
    "    knn_f1 = metrics.f1_score(dev_labels, knn_preds, average='weighted')\n",
    "    \n",
    "     \n",
    "    print \"  The F1 score for the nearest neighbor classifier is:\" + `knn_f1`\n",
    "    print \"\\n\"\n",
    "\n",
    "    \n",
    "    ########## MULTINOMIAL BAYES ###########\n",
    "    \n",
    "    alphas = {'alpha': [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "    mnb = MultinomialNB()\n",
    "    mnb_gs = GridSearchCV(mnb, alphas, scoring='f1_weighted')\n",
    "    mnb_gs.fit(train_data_cols, train_labels)\n",
    "    opt_alpha = mnb_gs.best_params_['alpha']\n",
    "    print \"\\nMultinomial Naive Bayes Classifier:\"\n",
    "    print \"  Optimal alpha for multinomial naive bayes classifier:\" + `opt_alpha`\n",
    "\n",
    "    mnb_opt = MultinomialNB(alpha = opt_alpha)\n",
    "    mnb_opt.fit(train_data_cols, train_labels)\n",
    "    mnb_preds = mnb_opt.predict(dev_data_cols)\n",
    "    mnb_f1 = metrics.f1_score(dev_labels, mnb_preds, average='weighted')\n",
    "    \n",
    "    print \"  The F1 score for the multinomial nb classifier is:\" + `mnb_f1`\n",
    "    print \"\\n\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    ######### LOGISTIC REGRESSION #########\n",
    "    \n",
    "    # Logistic Regression\n",
    "\n",
    "    C = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "    lr = LogisticRegression(penalty='l2')\n",
    "    lr_gs = GridSearchCV(lr, C, scoring='f1_weighted')\n",
    "    lr_gs.fit(train_data_cols, train_labels)\n",
    "    opt_C = lr_gs.best_params_['C']\n",
    "    print \"Logistic Regression Model:\"\n",
    "    print \"  Optimal C for logistic regression model is:\" + `opt_C`\n",
    "\n",
    "    lr_opt = LogisticRegression(C = opt_C, penalty='l2')\n",
    "    lr_opt.fit(train_data_cols, train_labels)\n",
    "    lr_preds = lr_opt.predict(dev_data_cols)\n",
    "    lr_f1 = metrics.f1_score(dev_labels, lr_preds, average='weighted')\n",
    "\n",
    "    print \"  The F1 score for the logistic regression classifier is:\" + `lr_f1`\n",
    "    print \"\\n\"\n",
    "    \n",
    "k_values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "P3(k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training/testing sets\n",
    "train_data_cols : diabetes_X_train = diabetes_X[:-20]\n",
    "dev_data_cols: diabetes_X_test = diabetes_X[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "train_labels : diabetes_y_train = diabetes.target[:-20]\n",
    "dev_labels: diabetes_y_test = diabetes.target[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2178\n",
      "2178\n"
     ]
    }
   ],
   "source": [
    "print len(dev_data_cols)\n",
    "print len(dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Coefficients: \\n', array([ 10.47037496]))\n",
      "('Coefficients: \\n', array([ 10.47037496]))\n",
      "Mean squared error: 27183.26\n",
      "Variance score: 0.16\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADuCAYAAAAOR30qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njEBBJoQQI/w/aacFGe2bu2kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ff88510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error is 64197.8191001 !!\n"
     ]
    }
   ],
   "source": [
    "##### LINEAR REGRESSION MODEL #####\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(train_data_cols, train_labels)\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % np.mean((regr.predict(dev_data_cols) - dev_labels) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % regr.score(dev_data_cols, dev_labels))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(dev_data_cols, dev_labels,  color='black')\n",
    "plt.plot(dev_data_cols, regr.predict(dev_data_cols), color='blue',\n",
    "         linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print 'Mean squared error is {} !!'.format(mean_squared_error(dev_labels, dev_data_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-60eb1edfd3dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gini'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Predict Output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/divyas/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/divyas/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/divyas/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    380\u001b[0m                                       force_all_finite)\n\u001b[1;32m    381\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "model = tree.DecisionTreeClassifier(criterion='gini')\n",
    "model.fit(train_data, train_labels)\n",
    "model.score(train_data, train_labels)\n",
    "#Predict Output\n",
    "predicted= model.predict(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNDERSTANDING RMSLE: \n",
    "\n",
    "https://www.slideshare.net/KhorSoonHin/rmsle-cost-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://technospeaknow.blogspot.in/2015/02/prediction-of-registered-bike-sharing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/bike-sharing-demand/discussion/9899#52134"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gist.github.com/rowanv/70a109b9a5d3a4630f5d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://www.analyticsvidhya.com/blog/2015/06/solution-kaggle-competition-bike-sharing-demand/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "http://www.techdreams.org/programming/solving-kaggles-bike-sharing-demand-machine-learning-problem/9343-20140821"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://www.kaggle.com/tianji/bike-rental-predictions-using-lr-rf-gbr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I used for rpart and party (R)\n",
    "http://brandonharris.io/kaggle-bike-sharing/\n",
    "\n",
    "Party provides an implementation of conditional inference trees. This is still recursive partitioning, similar to rpart, but there are a few important differences.\n",
    "\n",
    "rpart() tends to choose variables that will provide many possible splits when building the tree. This initial selection bias can work well sometimes, but in other cases can cause a loss of accuracy in the model. A conditional inference tree avoids this initial selection bias by using a permutation test framework to calculate statistics on the covariates, and then determine which our of independent variables might be the most appropriate for building our decision / regression tree. Plainly put, conditional inference trees are a bit more methodical when it comes to deciding which covariates are most important to our outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
